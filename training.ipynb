{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Try to use Colab"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# from google.colab import drive\r\n",
                "# drive.mount('/content/gdrive')\r\n",
                "# %cd /content/gdrive/My Drive\r\n",
                "# %rm -f -r mlmech\r\n",
                "# ! git clone https://github.com/jfra1397/mlmech.git\r\n",
                "# %cd mlmech"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# !git checkout main\r\n",
                "# !git pull"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Training starts here"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import custom\r\n",
                "import create_model\r\n",
                "from importlib import reload"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "reload(custom)\r\n",
                "from custom import *\r\n",
                "\r\n",
                "from load_data import CustomDataGenerator\r\n",
                "\r\n",
                "\r\n",
                "train, validation = CustomDataGenerator.generate_data(batch_size, img_dir, mask_dir,\r\n",
                "                                                        horizontal_split, vertical_split, image_extension, mask_extension, \r\n",
                "                                                        preprocess_fcn, validation_split=val_split, flip=True, shift = shift, onelabel=onelabel, seed=seed)# ,single_img=single_img)\r\n",
                "img_size = train.img_size\r\n",
                "print(img_size)\r\n",
                "mask_size = train.mask_size\r\n",
                "print(mask_size)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "train.plot_batch(3)\n",
                "\n",
                "img, mask = train.__getitem__(2)\n",
                "print(img.min())\n",
                "print(img.max())\n",
                "print(mask.min())\n",
                "print(mask.max())\n",
                "print(train.classes)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "reload(custom)\n",
                "from custom import *\n",
                "\n",
                "reload(create_model)\n",
                "from create_model import generate_model\n",
                "\n",
                "import tensorflow.keras.losses as losses\n",
                "\n",
                "model = generate_model(img_size)\n",
                "\n",
                "model.compile(optimizer='adam',\n",
                "                loss=loss,\n",
                "                metrics=['accuracy', dice_metric])\n",
                "model.summary()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "reload(custom)\r\n",
                "from custom import *\r\n",
                "\r\n",
                "history = model.fit(x=train, validation_data = validation, epochs=epochs, steps_per_epoch=steps_per_epoch, verbose=1, shuffle=True, callbacks=callback)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "plt.figure(figsize=(12,7))\r\n",
                "plt.plot(history.history[\"loss\"], lw=4, label=\"loss\")\r\n",
                "plt.plot(history.history[\"val_loss\"], lw=4, label=\"val_loss\")\r\n",
                "plt.legend()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "images, masks = train.__getitem__(2)\n",
                "preds = model.predict(x=images, verbose=1)\n",
                "\n",
                "train.plot_prediction(2, preds)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "reload(custom)\r\n",
                "from custom import *\r\n",
                "\r\n",
                "import pandas as pd\r\n",
                "import os\r\n",
                "\r\n",
                "os.mkdir(dir_name)\r\n",
                "\r\n",
                "from shutil import copyfile\r\n",
                "copyfile(\"custom.py\", dir_name + \"/custom.py\")\r\n",
                "copyfile(\"create_model.py\", dir_name + \"/create_model.py\")\r\n",
                "\r\n",
                "\r\n",
                "# convert the history.history dict to a pandas DataFrame:     \r\n",
                "hist_df = pd.DataFrame(history.history) \r\n",
                "\r\n",
                "# save to json:  \r\n",
                "hist_json_file = dir_name + '/history.json' \r\n",
                "with open(hist_json_file, mode='w') as f:\r\n",
                "    hist_df.to_json(f)\r\n",
                "\r\n",
                "#save model\r\n",
                "model.save(dir_name + \"/model.tf\", include_optimizer = True)\r\n",
                "model.save_weights(dir_name + \"/weights.tf\")"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit (windows store)"
        },
        "interpreter": {
            "hash": "3a15bfa232e543687314c1f481ee600349622b18d0cc918f4ae52f745c138b07"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}