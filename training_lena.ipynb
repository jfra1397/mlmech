{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Try to use Colab"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from google.colab import drive\r\n",
                "drive.mount('/content/gdrive')\r\n",
                "%cd /content/gdrive/My Drive\r\n",
                "%rm -f -r mlmech\r\n",
                "! git clone https://github.com/jfra1397/mlmech.git\r\n",
                "%cd mlmech"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "!git checkout main\r\n",
                "!git pull"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Training starts here"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import custom\r\n",
                "import create_model\r\n",
                "from importlib import reload"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "reload(custom)\r\n",
                "from custom import *\r\n",
                "\r\n",
                "from load_data_lena import CustomDataGenerator\r\n",
                "\r\n",
                "\r\n",
                "img_dir = \"images/\"\r\n",
                "mask_dir = \"labels/\"\r\n",
                "image_extension = \".png\"\r\n",
                "mask_extension = \".png\"\r\n",
                "img_size = (256, 256)\r\n",
                "#batch_size = 16\r\n",
                "horizontal_split = 12\r\n",
                "vertical_split = 1\r\n",
                "\r\n",
                "train, validation = CustomDataGenerator.generate_data(batch_size, img_dir, mask_dir,\r\n",
                "                                                        horizontal_split, vertical_split, image_extension, mask_extension, \r\n",
                "                                                        preprocess_fcn, validation_split=0.1, flip=True, shift = shift, onelabel=onelabel, seed=seed)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of samples:  5400\n",
                        "Classes: [0 1]\n",
                        "Number of samples:  600\n",
                        "Classes: [0 1]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "#train.plot_batch(3)\r\n",
                "\r\n",
                "img, mask = train.__getitem__(2)\r\n",
                "print(img.min())\r\n",
                "print(img.max())\r\n",
                "print(mask.min())\r\n",
                "print(mask.max())\r\n",
                "print(train.classes)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "-1.0\n",
                        "1.0\n",
                        "0.0\n",
                        "1.0\n",
                        "[0 1]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "#from keras import backend\r\n",
                "#K = keras.backend.backend()\r\n",
                "import tensorflow as tf\r\n",
                "\r\n",
                "reload(custom)\r\n",
                "from custom import *\r\n",
                "\r\n",
                "reload(create_model)\r\n",
                "#from create_model import generate_model\r\n",
                "\r\n",
                "import tensorflow.keras.losses as losses\r\n",
                "from tensorflow.keras import backend\r\n",
                "\r\n",
                "#model = generate_model()\r\n",
                "#from segnet_model2 import create_segnet\r\n",
                "#from segnet_model import create_segnet\r\n",
                "#from segnet_model_lenaWithLayers_ import create_segnet\r\n",
                "from segnetSimple import create_segnet\r\n",
                "#from segnet_vgg16_001 import SegNet_VGG16\r\n",
                "\r\n",
                "if onelabel == True:\r\n",
                "    n_labels = 1\r\n",
                "else:\r\n",
                "    n_labels = 3\r\n",
                "model = create_segnet(input_shape=(256,256,3), n_labels=n_labels, output_mode=\"sigmoid\")\r\n",
                "#model = SegNet_VGG16(input_shape=(256,256,3), num_classes=n_labels)\r\n",
                "\r\n",
                "#model = create_segnet(input_shape=(256,256,3), n_labels=n_labels, output_mode=\"softmax\")\r\n",
                "#model = create_segnet(input_shape=(256,256,3), n_labels=n_labels, output_mode=\"softmax\")\r\n",
                "#model = SegNet(input_shape=(256,256,3), classes=n_labels)\r\n",
                "#from segnet4 import segnet\r\n",
                "\r\n",
                "#from unetsegnet import generate_model\r\n",
                "#model = generate_model()\r\n",
                "\r\n",
                "\r\n",
                "#model = segnet(input_shape=(256,256,3), n_labels=n_labels)\r\n",
                "\r\n",
                "#opti = tf.keras.optimizers.Adam(learning_rate=0.01)\r\n",
                "model.compile(optimizer='adam',\r\n",
                "                loss=loss,\r\n",
                "                metrics=['accuracy'])\r\n",
                "\r\n",
                "model.summary()\r\n",
                "#print(model.optimizer.learning_rate.numpy())\r\n",
                "#backend.set_value(model.optimizer.learning_rate, 0.01)\r\n",
                "print(model.optimizer.learning_rate.numpy())\r\n",
                "\r\n",
                "#from segnet_test import *\r\n",
                "\r\n",
                "#test_max_pooling_argmax()\r\n",
                "\r\n",
                "#test_max_unpooling()\r\n",
                "\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Model: \"functional_1\"\n",
                        "__________________________________________________________________________________________________\n",
                        "Layer (type)                    Output Shape         Param #     Connected to                     \n",
                        "==================================================================================================\n",
                        "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
                        "__________________________________________________________________________________________________\n",
                        "conv2d (Conv2D)                 (None, 256, 256, 32) 896         input_1[0][0]                    \n",
                        "__________________________________________________________________________________________________\n",
                        "batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv2d[0][0]                     \n",
                        "__________________________________________________________________________________________________\n",
                        "activation (Activation)         (None, 256, 256, 32) 0           batch_normalization[0][0]        \n",
                        "__________________________________________________________________________________________________\n",
                        "max_pooling_with_indices2d (Max [(None, 128, 128, 32 0           activation[0][0]                 \n",
                        "__________________________________________________________________________________________________\n",
                        "conv2d_1 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling_with_indices2d[0][0] \n",
                        "__________________________________________________________________________________________________\n",
                        "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n",
                        "__________________________________________________________________________________________________\n",
                        "activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
                        "__________________________________________________________________________________________________\n",
                        "max_pooling_with_indices2d_1 (M [(None, 64, 64, 64), 0           activation_1[0][0]               \n",
                        "__________________________________________________________________________________________________\n",
                        "conv2d_2 (Conv2D)               (None, 64, 64, 64)   36928       max_pooling_with_indices2d_1[0][0\n",
                        "__________________________________________________________________________________________________\n",
                        "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
                        "__________________________________________________________________________________________________\n",
                        "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
                        "__________________________________________________________________________________________________\n",
                        "max_pooling_with_indices2d_2 (M [(None, 32, 32, 64), 0           activation_2[0][0]               \n",
                        "__________________________________________________________________________________________________\n",
                        "conv2d_3 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling_with_indices2d_2[0][0\n",
                        "__________________________________________________________________________________________________\n",
                        "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         conv2d_3[0][0]                   \n",
                        "__________________________________________________________________________________________________\n",
                        "activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_3[0][0]      \n",
                        "__________________________________________________________________________________________________\n",
                        "max_pooling_with_indices2d_3 (M [(None, 16, 16, 128) 0           activation_3[0][0]               \n",
                        "__________________________________________________________________________________________________\n",
                        "max_unpooling_with_indices2d (M (None, 32, 32, 128)  0           max_pooling_with_indices2d_3[0][0\n",
                        "                                                                 max_pooling_with_indices2d_3[0][1\n",
                        "__________________________________________________________________________________________________\n",
                        "conv2d_4 (Conv2D)               (None, 32, 32, 64)   73792       max_unpooling_with_indices2d[0][0\n",
                        "__________________________________________________________________________________________________\n",
                        "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
                        "__________________________________________________________________________________________________\n",
                        "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
                        "__________________________________________________________________________________________________\n",
                        "max_unpooling_with_indices2d_1  (None, 64, 64, 64)   0           activation_4[0][0]               \n",
                        "                                                                 max_pooling_with_indices2d_2[0][1\n",
                        "__________________________________________________________________________________________________\n",
                        "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       max_unpooling_with_indices2d_1[0]\n",
                        "__________________________________________________________________________________________________\n",
                        "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_5[0][0]                   \n",
                        "__________________________________________________________________________________________________\n",
                        "activation_5 (Activation)       (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
                        "__________________________________________________________________________________________________\n",
                        "max_unpooling_with_indices2d_2  (None, 128, 128, 64) 0           activation_5[0][0]               \n",
                        "                                                                 max_pooling_with_indices2d_1[0][1\n",
                        "__________________________________________________________________________________________________\n",
                        "conv2d_6 (Conv2D)               (None, 128, 128, 32) 18464       max_unpooling_with_indices2d_2[0]\n",
                        "__________________________________________________________________________________________________\n",
                        "batch_normalization_6 (BatchNor (None, 128, 128, 32) 128         conv2d_6[0][0]                   \n",
                        "__________________________________________________________________________________________________\n",
                        "activation_6 (Activation)       (None, 128, 128, 32) 0           batch_normalization_6[0][0]      \n",
                        "__________________________________________________________________________________________________\n",
                        "max_unpooling_with_indices2d_3  (None, 256, 256, 32) 0           activation_6[0][0]               \n",
                        "                                                                 max_pooling_with_indices2d[0][1] \n",
                        "__________________________________________________________________________________________________\n",
                        "conv2d_7 (Conv2D)               (None, 256, 256, 1)  33          max_unpooling_with_indices2d_3[0]\n",
                        "__________________________________________________________________________________________________\n",
                        "batch_normalization_7 (BatchNor (None, 256, 256, 1)  4           conv2d_7[0][0]                   \n",
                        "__________________________________________________________________________________________________\n",
                        "activation_7 (Activation)       (None, 256, 256, 1)  0           batch_normalization_7[0][0]      \n",
                        "==================================================================================================\n",
                        "Total params: 261,189\n",
                        "Trainable params: 260,291\n",
                        "Non-trainable params: 898\n",
                        "__________________________________________________________________________________________________\n",
                        "0.001\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "reload(custom)\r\n",
                "from custom import *\r\n",
                "\r\n",
                "history = model.fit(x=train, validation_data = validation, epochs=epochs, steps_per_epoch=steps_per_epoch, verbose=1, shuffle=True)#callbacks=[callback], verbose=1, shuffle=True)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 1/50\n",
                        "12/20 [=================>............] - ETA: 35s - loss: 5.7901 - accuracy: 0.6203"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-5-064d25f1f163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcustom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#callbacks=[callback], verbose=1, shuffle=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "plt.figure(figsize=(12,7))\r\n",
                "plt.plot(history.history[\"loss\"], lw=4, label=\"loss\")\r\n",
                "plt.plot(history.history[\"val_loss\"], lw=4, label=\"val_loss\")\r\n",
                "plt.legend()\r\n",
                "#plt.ylim(top=1.5, bottom=0.4)\r\n",
                "plt.savefig(\"loss.png\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "images, masks = train.__getitem__(6)\r\n",
                "preds = model.predict(x=images, verbose=1)\r\n",
                "#print(preds[1])\r\n",
                "\r\n",
                "train.plot_prediction(6, preds)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "reload(custom)\r\n",
                "from custom import *\r\n",
                "\r\n",
                "import pandas as pd\r\n",
                "import os\r\n",
                "\r\n",
                "os.mkdir(dir_name)\r\n",
                "\r\n",
                "from shutil import copyfile\r\n",
                "copyfile(\"custom.py\", dir_name + \"/custom.py\")\r\n",
                "copyfile(\"create_model.py\", dir_name + \"/create_model.py\")\r\n",
                "\r\n",
                "\r\n",
                "# convert the history.history dict to a pandas DataFrame:     \r\n",
                "hist_df = pd.DataFrame(history.history) \r\n",
                "\r\n",
                "# save to json:  \r\n",
                "hist_json_file = dir_name + '/history.json' \r\n",
                "with open(hist_json_file, mode='w') as f:\r\n",
                "    hist_df.to_json(f)\r\n",
                "\r\n",
                "#save model\r\n",
                "model.save(dir_name + \"/model.tf\", include_optimizer = True)\r\n",
                "model.save_weights(dir_name + \"/weights.tf\")"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.0",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.0 64-bit"
        },
        "interpreter": {
            "hash": "c9afa6a7749aadf074a873cb62a73f97463505bdb20c04f202f2ef6050b7d5d3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}