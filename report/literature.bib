% This file was created with Citavi 6.3.0.0

@article{Badrinarayanan.2017,
 author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
 year = {2017},
 title = {SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation},
 url = {https://openaccess.thecvf.com/content_CVPR_2019/papers/Tian_Decoders_Matter_for_Semantic_Segmentation_Data-Dependent_Decoding_Enables_Flexible_Feature_CVPR_2019_paper.pdf},
 pages = {2481--2495},
 volume = {39},
 number = {12},
 issn = {0162-8828},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 doi = {10.1109/TPAMI.2016.2644615}
}


@article{JonathanLong.,
 abstract = {2015 IEEE Conference on Computer Vision and Pattern Recognition},
 author = {{Jonathan Long} and {Evan Shelhamer} and {Trevor Darrell}},
 title = {Fully Convolutional Networks for Semantic Segmentation},
 journal = {Artifical Intelligence Review},
 year = {2015},
 pages = {1â€“54},
 volume = {34},
 urldate = {24.08.2021}
}


@misc{Ronneberger.2015,
 abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at this http URL .},
 author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
 date = {2015},
 title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
 url = {https://arxiv.org/pdf/1505.04597},
 keywords = {Computer Vision and Pattern Recognition (cs.CV)}
}


@article{Saood.2021,
 author = {Saood, Adnan and Hatem, Iyad},
 year = {2021},
 title = {COVID-19 lung CT image segmentation using deep learning methods: U-Net versus SegNet},
 volume = {21},
 number = {1},
 journal = {BMC Medical Imaging},
 doi = {10.1186/s12880-020-00529-5}
}


@misc{Springenberg.2014,
 abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the {\textquotedbl}deconvolution approach{\textquotedbl} for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
 author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
 date = {2014},
 title = {Striving for Simplicity: The All Convolutional Net},
 url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf},
 keywords = {Computer Vision and Pattern Recognition (cs.CV);Machine Learning (cs.LG);Neural and Evolutionary Computing (cs.NE)}
}


@InProceedings{ZhiTian.,
    author = {Tian, Zhi and He, Tong and Shen, Chunhua and Yan, Youliang},
    title = {Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2019}
} 

@misc{he2016identity,
    title={Identity Mappings in Deep Residual Networks}, 
    author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    year={2016},
    eprint={1603.05027},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{simonyan2015deep,
    title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
    author={Karen Simonyan and Andrew Zisserman},
    year={2015},
    eprint={1409.1556},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{sandler2019mobilenetv2,
    title={MobileNetV2: Inverted Residuals and Linear Bottlenecks}, 
    author={Mark Sandler and Andrew Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
    year={2019},
    eprint={1801.04381},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@InProceedings{He_2016_CVPR,
    author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
    title = {Deep Residual Learning for Image Recognition},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2016}
} 